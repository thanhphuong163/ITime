{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSA ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# import ipywidgets as widgets\n",
    "# import bqplot.pyplot as bqplt\n",
    "# from tqdm.notebook import tqdm\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "# import tensorflow as tf\n",
    "# ['all', 'last', 'last_expr', 'none', 'last_expr_or_assign']\n",
    "InteractiveShell.ast_node_interactivity = \"last\"\n",
    "# matplotlib configuration\n",
    "mpl.rcParams['grid.color'] = 'k'\n",
    "mpl.rcParams['grid.linestyle'] = ':'\n",
    "mpl.rcParams['grid.linewidth'] = 0.5\n",
    "mpl.rcParams['font.size'] = 12\n",
    "# plt.style.use(['dark_background'])\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DSA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a01...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a02...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a03...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a04...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a05...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a06...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a07...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a08...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a09...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a10...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a11...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a12...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a13...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a14...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a15...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a16...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a17...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a18...\n",
      "Loading /home/tuangroup/ntphuong/projects/MVAD/raw_datasets/dsa/a19...\n"
     ]
    }
   ],
   "source": [
    "%run ../src/dsa_loader.py\n",
    "\n",
    "raw_data_dir = \"../raw_datasets/dsa\"\n",
    "clusters = [f\"a{i:02d}\" for i in range(1, 19+1)]\n",
    "dsa_dataset = DSADataset(raw_data_dir, activities=clusters)\n",
    "train_object_dfs, test_object_dfs = dsa_dataset.load_data()\n",
    "train_views_dfs = dsa_dataset.split_views(train_object_dfs)\n",
    "test_views_dfs = dsa_dataset.split_views(test_object_dfs)\n",
    "stored_dir = '../preprocessed_datasets/dsa'\n",
    "dsa_dataset.save_into_features(stored_dir, train_views_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc</th>\n",
       "      <th>T_yacc</th>\n",
       "      <th>T_zacc</th>\n",
       "      <th>T_xgyro</th>\n",
       "      <th>T_ygyro</th>\n",
       "      <th>T_zgyro</th>\n",
       "      <th>T_xmag</th>\n",
       "      <th>T_ymag</th>\n",
       "      <th>T_zmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.7247</td>\n",
       "      <td>2.1367</td>\n",
       "      <td>3.8272</td>\n",
       "      <td>0.29438</td>\n",
       "      <td>-0.251680</td>\n",
       "      <td>-0.150600</td>\n",
       "      <td>-0.57701</td>\n",
       "      <td>0.108630</td>\n",
       "      <td>-0.69680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.6209</td>\n",
       "      <td>2.0501</td>\n",
       "      <td>3.4529</td>\n",
       "      <td>0.23001</td>\n",
       "      <td>-0.260090</td>\n",
       "      <td>-0.132450</td>\n",
       "      <td>-0.58647</td>\n",
       "      <td>0.097419</td>\n",
       "      <td>-0.69026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.9343</td>\n",
       "      <td>2.0483</td>\n",
       "      <td>3.2762</td>\n",
       "      <td>0.20865</td>\n",
       "      <td>-0.343770</td>\n",
       "      <td>-0.101090</td>\n",
       "      <td>-0.59622</td>\n",
       "      <td>0.089638</td>\n",
       "      <td>-0.68402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0687</td>\n",
       "      <td>2.0770</td>\n",
       "      <td>3.2327</td>\n",
       "      <td>0.19724</td>\n",
       "      <td>-0.240970</td>\n",
       "      <td>-0.061406</td>\n",
       "      <td>-0.60466</td>\n",
       "      <td>0.082541</td>\n",
       "      <td>-0.67536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0529</td>\n",
       "      <td>1.9801</td>\n",
       "      <td>3.4110</td>\n",
       "      <td>0.23849</td>\n",
       "      <td>-0.098035</td>\n",
       "      <td>-0.009065</td>\n",
       "      <td>-0.61008</td>\n",
       "      <td>0.075034</td>\n",
       "      <td>-0.67158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_xacc  T_yacc  T_zacc  T_xgyro   T_ygyro   T_zgyro   T_xmag    T_ymag  \\\n",
       "0  8.7247  2.1367  3.8272  0.29438 -0.251680 -0.150600 -0.57701  0.108630   \n",
       "1  8.6209  2.0501  3.4529  0.23001 -0.260090 -0.132450 -0.58647  0.097419   \n",
       "2  8.9343  2.0483  3.2762  0.20865 -0.343770 -0.101090 -0.59622  0.089638   \n",
       "3  9.0687  2.0770  3.2327  0.19724 -0.240970 -0.061406 -0.60466  0.082541   \n",
       "4  9.0529  1.9801  3.4110  0.23849 -0.098035 -0.009065 -0.61008  0.075034   \n",
       "\n",
       "    T_zmag  \n",
       "0 -0.69680  \n",
       "1 -0.69026  \n",
       "2 -0.68402  \n",
       "3 -0.67536  \n",
       "4 -0.67158  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_views_dfs['view_1']['a09_p1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_scores(view, feature, instances):\n",
    "    score_path = f\"/home/tuangroup/ntphuong/projects/MVAD/preprocessed_datasets/dsa/gen_data/{view}/{feature}_saved_scores.json\"\n",
    "    with open(score_path, 'r') as f:\n",
    "        saved_scores = json.load(f)\n",
    "    anomaly_scores_np = np.array([saved_score[1] for saved_score in saved_scores])\n",
    "    print(anomaly_scores_np.shape)\n",
    "    anomaly_scores = pd.DataFrame(anomaly_scores_np.T, columns=[f'{i}' for i in instances])\n",
    "    return anomaly_scores\n",
    "\n",
    "def plot_instance(instance, view, feature, instances):\n",
    "    anomaly_score = get_scores(view, feature, instances)\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(20, 7*2))\n",
    "    data = train_views_dfs[view][instance][feature]\n",
    "    axs[0].plot(data)\n",
    "    predict_indices = anomaly_score[instance].sort_values(ascending=False)[:100].index\n",
    "    axs[0].scatter(predict_indices, data[predict_indices], c='r')\n",
    "    # new_data = data.copy(deep=True)\n",
    "    # for idx in predict_indices:\n",
    "    #     new_data[idx] = 0.\n",
    "    # axs[1].plot(new_data)\n",
    "    axs[1].plot(anomaly_score[instance])\n",
    "    plt.show()\n",
    "\n",
    "def replace_anomaly_values(view, feature, instances):\n",
    "    anomaly_scores = get_scores(view, feature, instances)\n",
    "    for instance in instances:\n",
    "        predict_indices = anomaly_scores[instance].sort_values(ascending=False)[:20].index\n",
    "        for idx in predict_indices:\n",
    "            train_views_dfs[view][instance][feature][idx] = np.nan\n",
    "            test_views_dfs[view][instance][feature][idx] = np.nan\n",
    "        # train_views_dfs[view][instance].fillna(method='ffill', inplace=True)\n",
    "        # test_views_dfs[view][instance].fillna(method='ffill', inplace=True)\n",
    "        # NOTE: We use linear method since it is the only method that supports MultiIndexes\n",
    "        train_views_dfs[view][instance].interpolate(method='linear', inplace=True)\n",
    "        test_views_dfs[view][instance].interpolate(method='linear', inplace=True)\n",
    "        \n",
    "\n",
    "\n",
    "# instance = 'a01_p10'\n",
    "# view = 'view_2'\n",
    "# feature = 'mag_lankle_y'\n",
    "# instances = sorted(list(train_views_dfs['view_1'].keys()))\n",
    "# plot_instance(instance, view, feature, instances)\n",
    "# replace_anomaly_values(view, feature, instances)\n",
    "# plot_instance(instance, view, feature, instances)\n",
    "for view, view_dfs in train_views_dfs.items():\n",
    "    instances = sorted(list(train_views_dfs[view].keys()))\n",
    "    for feature in view_dfs[instances[0]].columns:\n",
    "        replace_anomaly_values(view, feature, instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3750, 9)\n",
      "(3750, 9)\n"
     ]
    }
   ],
   "source": [
    "for view in train_views_dfs.keys():\n",
    "    for instance in train_views_dfs['view_1'].keys():\n",
    "        train_views_dfs[view][instance] = pd.DataFrame(train_views_dfs[view][instance][:3750].values, columns=train_views_dfs[view][instance].columns)\n",
    "        test_views_dfs[view][instance] = pd.DataFrame(test_views_dfs[view][instance][3750:].values, columns=test_views_dfs[view][instance].columns)\n",
    "print(train_views_dfs['view_1']['a01_p1'].shape)\n",
    "print(test_views_dfs['view_1']['a01_p1'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:02<00:00, 55.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:05<00:00, 29.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:07<00:00, 19.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:10<00:00, 14.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:02<00:00, 57.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:05<00:00, 29.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:07<00:00, 19.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:10<00:00, 14.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:03<00:00, 45.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:05<00:00, 29.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:08<00:00, 17.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:10<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:02<00:00, 59.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:05<00:00, 28.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:07<00:00, 19.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:10<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:03<00:00, 43.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:05<00:00, 29.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:08<00:00, 18.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n",
      "Generating anomalies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:10<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "%run ../src/anomaly_generations.py\n",
    "\n",
    "dataset_name = 'dsa_timestep_same_subject_random_view'\n",
    "n_samples = 10\n",
    "nb_views = 5\n",
    "\n",
    "for sample in range(11, n_samples+1):\n",
    "    for anomaly_rate in [5, 10, 15, 20]:\n",
    "        dir_path = f\"../preprocessed_datasets/{dataset_name}/sample{sample}/anomaly_rate_{anomaly_rate}_views_{nb_views}\"\n",
    "        swapped_test_views_dfs, ground_truths = swap_time_steps(copy.deepcopy(test_views_dfs), clusters=clusters, anomaly_rate=anomaly_rate*0.01)\n",
    "        # Save to files\n",
    "        print(\"Saving files...\")\n",
    "        for view, view_dfs in train_views_dfs.items():\n",
    "            view_path = dir_path+f\"/train/{view}\"\n",
    "            if not os.path.exists(view_path): os.makedirs(view_path)\n",
    "            for ap, df in view_dfs.items():\n",
    "                df.to_csv(f\"{view_path}/{ap}.csv\", index=False)\n",
    "        for view, view_dfs in swapped_test_views_dfs.items():\n",
    "            view_path = dir_path+f\"/test/{view}\"\n",
    "            if not os.path.exists(view_path):\n",
    "                os.makedirs(view_path)\n",
    "            for ap, df in view_dfs.items():\n",
    "                df.to_csv(f\"{view_path}/{ap}.csv\", index=False)\n",
    "        for ap, gt in ground_truths.items():\n",
    "            gt.to_csv(dir_path+f\"/test/{ap}.csv\", index=False)\n",
    "        print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ee41a881656f5fc4dd86b207feac279397358c077bb0ebe254df13365e193ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
